What is Kafka?

Kafka is a fast, scalable, durable, and fault-tolerant publish-subscribe messaging system. It is often used in real-time streaming data architectures to provide real-time analytics.

Kafka Use Cases
In short, Kafka is used for stream processing, website activity tracking, metrics collection and monitoring, log aggregation, real-time analytics, CEP, ingesting data into Spark, ingesting data into Hadoop, CQRS, replay messages, error recovery, and guaranteed distributed commit log for in-memory computing (microservices).

------------------------------------------------------------------------------------------------------

What is consistent hashing?

Consistent Hashing is a distributed hashing scheme that operates independently of the number of servers or objects in a distributed hash table by assigning them a position on an abstract circle, or hash ring. This allows servers and objects to scale without affecting the overall system.
https://www.toptal.com/big-data/consistent-hashing


------------------------------------------------------------------------------------------------------

What is a load balancer?
A load balancer is a device that distributes network or application traffic across a cluster of servers. Load balancing improves responsiveness and increases availability of applications.
https://www.citrix.com/en-in/glossary/load-balancing.html


------------------------------------------------------------------------------------------------------


What is Hadoop?
It is an open-source data platform or framework developed in Java, dedicated to store and analyze the large sets of unstructured data.


What is CDN?
Content Delivery Network.
A distributed data delivery network all around the world, holding duplicate data so that data does not have to travel large distances no matter where the end user is. It is used often for data that is in high demand, e.g. viral YouTube videos.


What is EC2 and S3?
EC2 = scalable computing
S3 = scalable storage
Both are Cloud services provided by Amazon


What are the general things we can do to reduce potential problems as systems become more complex?
 - Don't use centralized DBs
 - Use microservices
 - Use containers


What are the features of a microservice?
 - Microservices remove the database as a coupling device. The scary and counter-intuitive idea is that each service has its own database.
 - Microservices gives each team and independent ability to change what they do.
 - Lowering friction allows change to happen faster.
 - A microservice does one thing well.
 - A microservice is independently deployable. A federated architecture. Services can be deployed independently of any other service, with the constraint that they donâ€™t break their service contract.
 - A micro service is created by a small team that contains all the skills necessary to build, deploy, and manage the service. The team has end-to-end responsibility for the service.



A good tip about about microservices: Microservices usually grow successfully from monoliths. Success stories come from companies that started with monoliths because they were able to learn their domain and make good decisions about microservice partitions.



What is GFS?
A shared disk cluster file system used on Linux machines.



A good tip about accessing large amounts of data - any data which is massive and accessed often are better to be saved in RAM memory than in DB. For example, a Twitter user's home page.
Examples of tools that help store in RAM memory are MemCache and Redis.
How to use these softwares effectively - check if a datum is available in Memcache. If not, query from DB and store in MemCache. Now it can be accessed from MemCache frequently. Now also add an expiration date on this datum, so that if it has not been accessed for a while then it can be deleted from MemCache automatically.


Replication - Copying of data to multiple machines in case one or more them fail.

Consistency - When all machines/nodes in a cluster have the same data, so that you read/write from any of them.

Eventual consistency - when there is a time lapse before which all nodes in a cluster become consistent.

Availability - In the context of DBs, it refers to a cluster being always able to respond to queries, irrespective of some nodes going down.

Partition tolerance - A cluster is able to continue functioning even when two nodes are not able to communicate to each other (i.e., they got partitioned).

Vertical scaling - Increasing the resources of a server. e.g. the RAM, CPU.
Horizontal scaling - Increasing the number of servers.

Sharding -  With most huge systems, data does not fit on a single machine. In such cases, sharding refers to splitting the very large database into smaller, faster and more manageable parts called data shards.


CAP Theorem - It states that a distributed system cannot simultaneously guarantee all these 3 - consistency, availability, partition tolerance. http://ksat.me/a-plain-english-introduction-to-cap-theorem/


The advantage of a slave-master DB setup:
Ignoring the step where data is replicated to the slaves, the master is mainly used for write operations while the slaves are mainly used for read operations. This makes operations faster.
Also, since the master is being continuously used for write operations, the disk head does not need to go back and forth over the disk to find the right place to write data. It always starts close to where it left off. This again makes it faster.
Then there's the obvious benefit of having backups. When the master goes down, a slave replaces it.


Shared Web Hosts vs Virtual Private Servers:
The 1st is sharing resources, like RAM and disk space among users. This is cheaper but slows in performance quickly.


Scaling:
 - When introducing multiple servers, you need to distribute client requests across them.
 - This is done using a load balancer.
 - This means that the clients now only need to know the IP address of the load balancer rather than multiple servers.
 - One problem with distributing requests across identical servers is that the load balancer needs to constantly ask each server 'how busy are you right now?', so that it can decide which server to send it to. An alternate to this would be to make one server for gifs, one for html, etc.
 - A DNS server and load balancer could be the same machine?

 - If you click a link on a website, we already know the name of the website and hence there's no need to query the DNS again. This saves time. The name can be stored in cache.

 - Another problem with distributing data over identical servers is that you could save partial data in each, like when you are adding items to a shopping cart. Each server could have only 1 item, and when you want to checkout most of the items would be missing.
 - One solution to this problem is that there could be one dedicated server for storing information related to 'state' or 'sessions'. This means that all the identical servers will store the items in shopping cart to the 'state' server. However, this isn't the best solution as it puts reliance one a single machine.
 - Another solution would be to use 'RAID' disks, where data is written to multiple disks at the same time.



Log files are ideally best store in compressed state, since they are not accessed often and a lot of space can be saved.
